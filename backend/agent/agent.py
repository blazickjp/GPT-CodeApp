# import os
import openai
import json

GPT_MODEL = "gpt-3.5-turbo-0613"  # or any other chat model you want to use
MAX_TOKENS = 1000  # or any other number of tokens you want to use
TEMPERATURE = 0.2  # or any other temperature you want to use


class CodingAgent:
    def __init__(self, memory_manager, functions=[None], callables=[None]):
        """
        Initializes a CodingAgent object.

        Args:
            memory_manager (MemoryManager): An instance of MemoryManager class for managing conversation history.
            functions (list, optional): A list of function objects that can be called by the agent. Defaults to None.
        """
        self.memory_manager = memory_manager
        self.functions = functions
        self.function_map = {
            func.__name__: func for func in callables
        }  # Create a map of function names to functions

    def query(self, input_text, function_call="auto"):
        """
        Conducts a conversation with the agent by providing an input text.

        Args:
            input_text (str): The user's input text.
            function_call (str, optional): The type of function call. Defaults to "auto".

        Returns:
            str: The output text generated by the agent.
        """
        print(f"Input Text: {input_text}")
        self.memory_manager.add_message("user", input_text)
        message_history = [
            {"role": i["role"], "content": i["content"]}
            for i in self.memory_manager.get_messages()
        ]

        func_call = {
            "name": None,
            "arguments": "",
        }

        for chunk in openai.ChatCompletion.create(
            model=GPT_MODEL,
            messages=message_history,
            functions=self.functions,
            function_call=function_call,
            max_tokens=MAX_TOKENS,
            temperature=TEMPERATURE,
            stream=True,
        ):
            delta = chunk["choices"][0].get("delta", {})
            if "function_call" in delta:
                if "name" in delta.function_call:
                    func_call["name"] = delta.function_call["name"]
                if "arguments" in delta.function_call:
                    func_call["arguments"] += delta.function_call["arguments"]
            if chunk.choices[0].finish_reason == "function_call":
                print(f"Func Call: {func_call}")
                function_response = {
                    "role": "assistant",
                    "content": json.dumps(
                        obj=self.function_map[func_call["name"]](func_call["arguments"])
                    ),
                }
                message_history.append(function_response)
                for chunk in openai.ChatCompletion.create(
                    model=GPT_MODEL,
                    messages=message_history,
                    functions=self.functions,
                    function_call=function_call,
                    max_tokens=MAX_TOKENS,
                    temperature=TEMPERATURE,
                    stream=True,
                ):
                    content = chunk["choices"][0].get("delta", {}).get("content")
                    yield content
            else:
                yield delta.get("content")
