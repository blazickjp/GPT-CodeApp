{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import memgpt.autogen.memgpt_agent as memgpt_autogen\n",
    "import memgpt.autogen.interface as autogen_interface \n",
    "import memgpt.agent as agent\n",
    "import memgpt.system as system\n",
    "import memgpt.utils as utils\n",
    "import memgpt.presets as presets\n",
    "import memgpt.constants as constants\n",
    "import memgpt.personas.personas as personas\n",
    "import memgpt.humans.humans as humans\n",
    "from memgpt.persistence_manager import InMemoryStateManager, InMemoryStateManagerWithPreloadedArchivalMemory, InMemoryStateManagerWithFaiss\n",
    "\n",
    "import os\n",
    "import autogen\n",
    "import asyncio\n",
    "from absl import app, flags\n",
    "\n",
    "config_list = [\n",
    "    {\n",
    "        'model': 'gpt-4',\n",
    "        'api_key': os.getenv('OPENAI_API_KEY'),\n",
    "    },\n",
    "]\n",
    "llm_config = {\"config_list\": config_list, \"seed\": 42}\n",
    "user_proxy = autogen.UserProxyAgent(\n",
    "    name=\"User_proxy\",\n",
    "    system_message=\"A human admin.\",\n",
    "    code_execution_config={\"last_n_messages\": 2, \"work_dir\": \"groupchat\"},\n",
    ")\n",
    "\n",
    "interface = autogen_interface.AutoGenInterface()\n",
    "persistence_manager = InMemoryStateManager()\n",
    "memgpt_agent = presets.use_preset(presets.DEFAULT, 'gpt-4', personas.get_persona_text(personas.DEFAULT), humans.get_human_text(humans.DEFAULT), interface, persistence_manager)\n",
    "\n",
    "# MemGPT coder\n",
    "coder = memgpt_autogen.MemGPTAgent(\n",
    "    name=\"MemGPT_coder\",\n",
    "    agent=memgpt_agent,\n",
    ")\n",
    "\n",
    "# non-MemGPT PM\n",
    "pm = autogen.AssistantAgent(\n",
    "    name=\"Product_manager\",\n",
    "    system_message=\"Creative in software product ideas.\",\n",
    "    llm_config=llm_config,\n",
    ")\n",
    "\n",
    "groupchat = autogen.GroupChat(agents=[user_proxy, coder, pm], messages=[], max_round=12)\n",
    "manager = autogen.GroupChatManager(groupchat=groupchat, llm_config=llm_config)\n",
    "\n",
    "user_proxy.initiate_chat(coder, message=\"First send the message 'Let's go Mario!'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User_proxy (to MemGPT_coder):\n",
      "\n",
      "First send the message 'Let's go Mario!'\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">>>>>>>> USING AUTO REPLY...\n",
      "MemGPT_coder (to User_proxy):\n",
      "\n",
      "\"Let's go Mario!\"\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "config_list = [\n",
    "    {\n",
    "        'model': 'gpt-4',\n",
    "        'api_key': os.getenv('OPENAI_API_KEY'),\n",
    "    },\n",
    "]\n",
    "llm_config = {\"config_list\": config_list, \"seed\": 42}\n",
    "user_proxy = autogen.UserProxyAgent(\n",
    "    name=\"User_proxy\",\n",
    "    system_message=\"A human admin.\",\n",
    "    code_execution_config={\"last_n_messages\": 2, \"work_dir\": \"groupchat\"},\n",
    ")\n",
    "\n",
    "interface = autogen_interface.AutoGenInterface()\n",
    "persistence_manager = InMemoryStateManager()\n",
    "memgpt_agent = presets.use_preset(presets.DEFAULT, 'gpt-4', personas.get_persona_text(personas.DEFAULT), humans.get_human_text(humans.DEFAULT), interface, persistence_manager)\n",
    "\n",
    "# MemGPT coder\n",
    "coder = memgpt_autogen.MemGPTAgent(\n",
    "    name=\"MemGPT_coder\",\n",
    "    agent=memgpt_agent,\n",
    ")\n",
    "\n",
    "# non-MemGPT PM\n",
    "pm = autogen.AssistantAgent(\n",
    "    name=\"Product_manager\",\n",
    "    system_message=\"Creative in software product ideas.\",\n",
    "    llm_config=llm_config,\n",
    ")\n",
    "\n",
    "groupchat = autogen.GroupChat(agents=[user_proxy, coder, pm], messages=[], max_round=12)\n",
    "manager = autogen.GroupChatManager(groupchat=groupchat, llm_config=llm_config)\n",
    "\n",
    "user_proxy.initiate_chat(coder, message=\"First send the message 'Let's go Mario!'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
